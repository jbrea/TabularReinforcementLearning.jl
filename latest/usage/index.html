<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Usage · Tabular Reinforcement Learning</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/highlightjs/default.css" rel="stylesheet" type="text/css"/><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Tabular Reinforcement Learning</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Introduction</a></li><li class="current"><a class="toctext" href>Usage</a><ul class="internal"><li><a class="toctext" href="#Simple-usage-1">Simple usage</a></li><li><a class="toctext" href="#Advanced-Usage-1">Advanced Usage</a></li><li><a class="toctext" href="#Comparisons-1">Comparisons</a></li><li><a class="toctext" href="#Examples-1">Examples</a></li></ul></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../comparison/">Comparison</a></li><li><a class="toctext" href="../learning/">Learning</a></li><li><a class="toctext" href="../learners/">Learners</a></li><li><a class="toctext" href="../policies/">Policies</a></li><li><a class="toctext" href="../mdp/">Environments</a></li><li><a class="toctext" href="../metrics/">Evaluation Metrics</a></li><li><a class="toctext" href="../stop/">Stopping Criteria</a></li><li><a class="toctext" href="../callbacks/">Callbacks</a></li></ul></li><li><a class="toctext" href="../api/">API</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Usage</a></li></ul><a class="edit-page" href="https://github.com/jbrea/TabularReinforcementLearning.jl/tree/9f93853c32a07452f903eccda299ab9ebef7d618/docs/src/usage.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Usage</span><a class="fa fa-bars" href="#"></a></div></header><h2><a class="nav-anchor" id="Simple-usage-1" href="#Simple-usage-1">Simple usage</a></h2><ol><li><p>Define an <a href="../learning/#TabularReinforcementLearning.Agent"><code>Agent</code></a>.</p></li><li><p>Choose an <a href="../mdp/#mdp-1">environment</a>.</p></li><li><p>Choose a <a href="../metrics/#metrics-1">metric</a>.</p></li><li><p>Choose a <a href="../stop/#stop-1">stopping criterion</a>.</p></li><li><p>(Optionally) define an <a href="../learning/#TabularReinforcementLearning.RLSetup"><code>RLSetup</code></a>.</p></li><li><p>Learn with <a href="../learning/#TabularReinforcementLearning.learn!-NTuple{6,Any}"><code>learn!</code></a>.</p></li><li><p>Look at results with <a href="../api/#TabularReinforcementLearning.getvalue"><code>getvalue</code></a>.</p></li></ol><p>Example</p><pre><code class="language-julia">agent = Agent(QLearning())
env = MDP()
metric = TotalReward()
stop = ConstantNumberSteps(100)
x = RLSetup(agent, env, metric, stop)
learn!(x)
getvalue(metric)</code></pre><h2><a class="nav-anchor" id="Advanced-Usage-1" href="#Advanced-Usage-1">Advanced Usage</a></h2><ol><li><p>Define an <a href="../learning/#TabularReinforcementLearning.Agent"><code>Agent</code></a> by choosing one of the <a href="../learners/#learners-1">learners</a>, one of the <a href="../policies/#policies-1">policies</a> and one of the <a href="../callbacks/#callbacks-1">callbacks</a> (e.g. to have an exploration schedule).</p></li><li><p>Choose an <a href="../mdp/#mdp-1">environment</a> or define the <a href="../api/#api_environments-1">interaction with a custom environment</a>.</p></li><li><p>( - 7.) as above.</p></li><li><p>(Optionally) compare with optimal solution.</p></li></ol><p>Example</p><pre><code class="language-julia">learner = QLearning(na = 5, ns = 500, λ = .8, γ = .95,
					tracekind = ReplacingTraces, initvalue = 10.)
policy = EpsilonGreedyPolicy(.2)
callback = ReduceEpsilonPerT(10^4)
agent = Agent(learner, policy, callback)
env = MDP(na = 5, ns = 500, init = &quot;deterministic&quot;)
metric = EvaluationPerT(10^4)
stop = ConstantNumberSteps(10^6)
x = RLSetup(agent, env, metric, stop)
@time learn!(x)
res = getvalue(metric)
mdpl = MDPLearner(env, .95)
policy_iteration!(mdpl)
reset!(env)
x2 = RLSetup(Agent(mdpl, EpsilonGreedyPolicy(.2), ReduceEpsilonPerT(10^4)), 
			 env, EvaluationPerT(10^4), ConstantNumberSteps(10^6))
run!(x2)
res2 = getvalue(x2.metric)</code></pre><h2><a class="nav-anchor" id="Comparisons-1" href="#Comparisons-1">Comparisons</a></h2><p>See section <a href="../comparison/#comparison-1"><code>Comparison</code></a>.</p><h2><a class="nav-anchor" id="Examples-1" href="#Examples-1">Examples</a></h2><p>See <a href="https://github.com/jbrea/TabularReinforcementLearning.jl/tree/master/examples">examples</a>.</p><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Introduction</span></a><a class="next" href="../comparison/"><span class="direction">Next</span><span class="title">Comparison</span></a></footer></article></body></html>
