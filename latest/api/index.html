<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · Tabular Reinforcement Learning</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Tabular Reinforcement Learning</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Introduction</a></li><li><a class="toctext" href="../usage/">Usage</a></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../comparison/">Comparison</a></li><li><a class="toctext" href="../learning/">Learning</a></li><li><a class="toctext" href="../learners/">Learners</a></li><li><a class="toctext" href="../policies/">Policies</a></li><li><a class="toctext" href="../mdp/">Environments</a></li><li><a class="toctext" href="../metrics/">Evaluation Metrics</a></li><li><a class="toctext" href="../stop/">Stopping Criteria</a></li><li><a class="toctext" href="../callbacks/">Callbacks</a></li></ul></li><li class="current"><a class="toctext" href>API</a><ul class="internal"><li><a class="toctext" href="#Learners-1">Learners</a></li><li><a class="toctext" href="#Policies-1">Policies</a></li><li><a class="toctext" href="#Callbacks-1">Callbacks</a></li><li><a class="toctext" href="#api_environments-1">Environments</a></li><li><a class="toctext" href="#Evaluation-Metrics-1">Evaluation Metrics</a></li><li><a class="toctext" href="#Stopping-Criteria-1">Stopping Criteria</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>API</a></li></ul><a class="edit-page" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/master/docs/src/api.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>API</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="API-1" href="#API-1">API</a></h1><p>New learners, policies, callbacks, environments, evaluation metrics or stopping criteria need to implement the following functions.</p><h2><a class="nav-anchor" id="Learners-1" href="#Learners-1">Learners</a></h2><p>Learners that require only a (state, action, reward) triple and possibly the next state and action should implement the first definition. If the learner is also to be used with a NstepLearner one also needs to implement the second  definition.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.update!" href="#TabularReinforcementLearning.update!"><code>TabularReinforcementLearning.update!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">update!(learner::TabularReinforcementLearning.AbstractReinforcementLearner, 
        r, s0, a0, s1, a1, iss0terminal)</code></pre><p>Update <code>learner</code> after observing state <code>s0</code>, performing action <code>a0</code>, receiving reward <code>r</code>, observing next state <code>s1</code> and performing next action <code>a1</code>. The boolean <code>iss0terminal</code> is <code>true</code> if <code>s0</code> is a terminal state.</p><pre><code class="language-none">update!(learner::Union{NstepLearner, EpisodicLearner}, 
        baselearner::TabularReinforcementLearning.AbstractReinforcementLearner, 
        rewards, states, actions, isterminal)</code></pre><p>Update <code>baselearner</code> with arrays of maximally <code>n+1</code> <code>states</code>, <code>n+1</code> <code>actions</code>, <code>n</code> rewards, if <code>learner</code> is <a href="../learners/#TabularReinforcementLearning.NstepLearner"><code>NstepLearner</code></a>. If <code>learner</code> is <a href="../learners/#TabularReinforcementLearning.EpisodicLearner"><code>EpisodicLearner</code></a> the arrays grow until the end of an episode. The boolean <code>isterminal</code> is <code>true</code> if <code>states[end-1]</code> is a terminal state.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L6-L23">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.act-Tuple{Any,Any,Any}" href="#TabularReinforcementLearning.act-Tuple{Any,Any,Any}"><code>TabularReinforcementLearning.act</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">act(learner::TabularReinforcementLearning.AbstractReinforcementLearner,
    policy::TabularReinforcementLearning.AbstractPolicy,
    state)</code></pre><p>Returns an action for a <code>learner</code>, using <code>policy</code> in <code>state</code>.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L31-L37">source</a></section><h2><a class="nav-anchor" id="Policies-1" href="#Policies-1">Policies</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.act-Tuple{Any,Any}" href="#TabularReinforcementLearning.act-Tuple{Any,Any}"><code>TabularReinforcementLearning.act</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">act(policy::TabularReinforcementLearning.AbstractPolicy, values)</code></pre><p>Returns an action given an array of <code>values</code> (one value for each possible action)  using <code>policy</code>.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L38-L43">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.getactionprobabilities" href="#TabularReinforcementLearning.getactionprobabilities"><code>TabularReinforcementLearning.getactionprobabilities</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">getactionprobabilities(policy::TabularReinforcementLearning.AbstractPolicy, values)</code></pre><p>Returns a array of action probabilities for a given array of <code>values</code>  (one value for each possible action) and <code>policy</code>.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L45-L50">source</a></section><h2><a class="nav-anchor" id="Callbacks-1" href="#Callbacks-1">Callbacks</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.callback!" href="#TabularReinforcementLearning.callback!"><code>TabularReinforcementLearning.callback!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">callback!(callback::AbstractCallback, learner, policy, r, a, s, isterminal)</code></pre><p>Can be used to manipulate the learner or the policy during learning, e.g. to change the learning rate or the exploration rate.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L113-L118">source</a></section><h2><a class="nav-anchor" id="api_environments-1" href="#api_environments-1">Environments</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.interact!" href="#TabularReinforcementLearning.interact!"><code>TabularReinforcementLearning.interact!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">interact!(action, environment)</code></pre><p>Updates the <code>environment</code> and returns the triple <code>state</code>, <code>reward</code>, <code>isterminal</code>,  where <code>state</code> is the new state of the environment (an integer), <code>reward</code> is the reward obtained for the performed <code>action</code> and <code>isterminal</code> is <code>true</code> if the  <code>state</code> is terminal.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L55-L62">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.getstate" href="#TabularReinforcementLearning.getstate"><code>TabularReinforcementLearning.getstate</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">getstate(environment)</code></pre><p>Returns the tuple <code>state</code>, <code>isterminal</code>. See also <a href="#TabularReinforcementLearning.interact!"><code>interact!(action, environment)</code></a>.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L64-L68">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.reset!" href="#TabularReinforcementLearning.reset!"><code>TabularReinforcementLearning.reset!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">reset!(environment)</code></pre><p>Resets the <code>environment</code> to a possible initial state.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L70-L74">source</a></section><h2><a class="nav-anchor" id="Evaluation-Metrics-1" href="#Evaluation-Metrics-1">Evaluation Metrics</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.evaluate!" href="#TabularReinforcementLearning.evaluate!"><code>TabularReinforcementLearning.evaluate!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">evaluate!(metric::TabularReinforcementLearning.AbstractEvaluationMetrics, 
          reward, action, state, isterminal)</code></pre><p>Updates the <code>metric</code> based on the experienced (<code>reward</code>, <code>action</code>, <code>state</code>) triplet and the boolean <code>isterminal</code> that is <code>true</code> if <code>state</code> is terminal.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L81-L88">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.getvalue" href="#TabularReinforcementLearning.getvalue"><code>TabularReinforcementLearning.getvalue</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">getvalue(metric)</code></pre><p>Returns the value of a metric.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L90-L94">source</a></section><h2><a class="nav-anchor" id="Stopping-Criteria-1" href="#Stopping-Criteria-1">Stopping Criteria</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="TabularReinforcementLearning.isbreak!" href="#TabularReinforcementLearning.isbreak!"><code>TabularReinforcementLearning.isbreak!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">isbreak!(criterion::TabularReinforcementLearning.StoppingCriterion, r, a, s, isterminal)</code></pre><p>Return <code>true</code> if <code>criterion</code> is matched. See <a href="../stop/#TabularReinforcementLearning.ConstantNumberSteps"><code>ConstantNumberSteps</code></a> and <a href="../stop/#TabularReinforcementLearning.ConstantNumberEpisodes"><code>ConstantNumberEpisodes</code></a> for builtin criterions and <a href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/master/examples/definestopcriterion.jl">example</a> for how to define new criterions.</p></div><a class="source-link" target="_blank" href="https://github.com/jbrea/TabularReinforcementLearning.jl/blob/3df48b95fc0e2799f54a85e8499265684ae074c1/src/abstracttypes.jl#L100-L107">source</a></section><footer><hr/><a class="previous" href="../callbacks/"><span class="direction">Previous</span><span class="title">Callbacks</span></a></footer></article></body></html>
